<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-architecture" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">High-Level Design | RAG Me Up</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://ragmeup.futureclub.nl/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://ragmeup.futureclub.nl/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://ragmeup.futureclub.nl/architecture"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="High-Level Design | RAG Me Up"><meta data-rh="true" name="description" content="The full high-level overview of RAG Me Up can be found in the drawing below. This image shows all components that can be used in the framework but all of them"><meta data-rh="true" property="og:description" content="The full high-level overview of RAG Me Up can be found in the drawing below. This image shows all components that can be used in the framework but all of them"><link data-rh="true" rel="icon" href="/img/favicon.png"><link data-rh="true" rel="canonical" href="https://ragmeup.futureclub.nl/architecture"><link data-rh="true" rel="alternate" href="https://ragmeup.futureclub.nl/architecture" hreflang="en"><link data-rh="true" rel="alternate" href="https://ragmeup.futureclub.nl/architecture" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.f30a109f.css">
<script src="/assets/js/runtime~main.35f4f969.js" defer="defer"></script>
<script src="/assets/js/main.f10be84c.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/favicon.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.png" alt="FC logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.png" alt="FC logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">RAG Me Up</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/">Documentation</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/FutureClubNL/RAGMeUp" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/">RAG Me Up Documentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/intro_rag">An introduction to RAG (and AI)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/architecture">High-Level Design</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/env">Configuring the .env File</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/running">Running RAG Me Up</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Indexing/loaders">Indexing</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">High-Level Design</span><meta itemprop="position" content="1"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>High-Level Design</h1></header>
<p>The full high-level overview of RAG Me Up can be found in the drawing below. This image shows all components that <em>can</em> be used in the framework but all of them
are configurable or can be turned on/off depending on your needs. Deciding which components you want to use and how to configure them, is crucial in setting up
production-grade RAG pipelines and will be explained for each component separately.</p>
<p>The entire RAG pipeline that will be executed by RAG Me Up can be configured through the <code>.env</code> file entirely. An example is given in <code>.env.template</code> which you
can rename to <code>.env</code>. The template aims to provide a sane starting point for generic RAG but should always be subject to tweaking when building your RAG setup.</p>
<p><img decoding="async" loading="lazy" alt="RAG pipeline drawing" src="/assets/images/ragmeup.drawio-f39f8b7c53e6c45e5cf02c9af7acb598.svg" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="high-level-pipeline-explanation">High Level Pipeline Explanation<a href="#high-level-pipeline-explanation" class="hash-link" aria-label="Direct link to High Level Pipeline Explanation" title="Direct link to High Level Pipeline Explanation">​</a></h2>
<p>Any RAG framework or pipeline roughly consists of two distinct sections:</p>
<ul>
<li>Indexing - a one-time process where a large corpus of documents is processed and indexed into a (vector) database. The whole indexing phase is executed <em>before</em> the query phase takes place.</li>
<li>Querying - a runtime process where a user initiaties a retrieval and answer process through an interaction. In this process, the indexes created during the indexing phase are used to retrieve documents and use those to answer the user&#x27;s query.</li>
</ul>
<p>While all of the components shown in the diagram will be discussed in the remainder in detail, we briefly address each below with links to subsections you can explore if you don&#x27;t want to read the documentation in full. Mind you that when using RAG Me Up, you will first and foremost be configuring the .env file which is a single place to set up all the components shown here.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="your-documents">Your Documents<a href="#your-documents" class="hash-link" aria-label="Direct link to Your Documents" title="Direct link to Your Documents">​</a></h3>
<p>Of course any RAG pipeline starts with your documents. While there are different flavors of RAG (GraphRAG, Text2SQL, etc.), RAG Me Up focuses on semantic RAG. This means that your documents and the queries you want to run on them should be semantic ones. Hence, your documents should contain some form of <em>text</em>. Whether that is inside a PDF, DOCX, JSON, CSV, etc. doesn&#x27;t matter but RAG Me Up does focus on text.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="loaders">Loaders<a href="#loaders" class="hash-link" aria-label="Direct link to Loaders" title="Direct link to Loaders">​</a></h3>
<p>For each document type (DOCX vs XLSX vs JSON, etc.), the way to retrieve the text from the source document differs. Hence, we have loaders for each type of document separately.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="chunking">Chunking<a href="#chunking" class="hash-link" aria-label="Direct link to Chunking" title="Direct link to Chunking">​</a></h3>
<p>A strength of RAG (when compared to &quot;just&quot; using an LLM and uploading a document) is that it is capable to search through large amounts of documents and also search <strong>within</strong> those documents. To achieve the latter, documents are chopped up into chunks. There are different ways of doing this chopping up and RAG Me Up supports a few.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="document-embeddings">Document Embeddings<a href="#document-embeddings" class="hash-link" aria-label="Direct link to Document Embeddings" title="Direct link to Document Embeddings">​</a></h3>
<p>Once we have our data chunked into parts of text, arguably the most crucial step is to convert them to vectors that we can use for comparison during query-time. RAG Me Up by uses hybrid search which combines dense and sparse vectors. The document embeddings are used to create the <strong>dense</strong> vectors using an LM or LLM<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sparse-bm25-vector-store">Sparse BM25 Vector store<a href="#sparse-bm25-vector-store" class="hash-link" aria-label="Direct link to Sparse BM25 Vector store" title="Direct link to Sparse BM25 Vector store">​</a></h3>
<p>One of the two ways chunks are indexed in RAG Me Up is using <a href="https://en.wikipedia.org/wiki/Okapi_BM25" target="_blank" rel="noopener noreferrer">BM25</a> as sparse vectors which typically excell at keyword-type search. This is useful for example when users query our RAG system with very brief, perhaps even single-word, queries that do not necessarily lead to meaningful embeddings.</p>
<p>RAG Me Up uses Postgres for storing sparse vectors with a BM25 index using <a href="https://docs.paradedb.com/welcome/introduction" target="_blank" rel="noopener noreferrer">pg_search by ParadeDB</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="dense-vector-db">Dense Vector DB<a href="#dense-vector-db" class="hash-link" aria-label="Direct link to Dense Vector DB" title="Direct link to Dense Vector DB">​</a></h3>
<p>The other way chunks are indexed in RAG Me Up is by writing the document embeddings created in the step before into an indexed database. For this, RAG Me Up also uses Postgres, indexed with the <a href="https://github.com/pgvector/pgvector" target="_blank" rel="noopener noreferrer">pgvector extension</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="query-user-interface">Query (User Interface)<a href="#query-user-interface" class="hash-link" aria-label="Direct link to Query (User Interface)" title="Direct link to Query (User Interface)">​</a></h3>
<p>Not explicitly written out in the diagram is the user interface. RAG Me Up comes with a custom user interface written in Scala to allow users to talk to the RAG system. RAG Me Up&#x27;s server (Python) is built to be stateless which means that the chat history, memory, previously retrieved documents, etc. are all supposed to be handled by the user interface.</p>
<p>An important part of the query handling step is to convert the user&#x27;s question into vectors that are similar to what is stored in the (vector) database. While not explicitly drawn in the architecture, we use the same embedding model to create the dense vector for the query.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="history-summarization">History Summarization<a href="#history-summarization" class="hash-link" aria-label="Direct link to History Summarization" title="Direct link to History Summarization">​</a></h3>
<p>While context windows of LLMs are ever increasing, they are still limited and even if they are really large, it becomes increasingly harder for an LLM to focus on the essence of a message as the size increases. Mind you also that in case of RAG Me Up, the chat history is part of every message sent to the LLM.</p>
<p>To remedy this, you can optionally summarize lengthy messages (with history) once they exceed a specific threshold.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="document-fetch-check">Document Fetch Check<a href="#document-fetch-check" class="hash-link" aria-label="Direct link to Document Fetch Check" title="Direct link to Document Fetch Check">​</a></h3>
<p>When dealing with history in a RAG system, it is important to determine whether or not a question from a user is actually a follow-up on documents that were already retrieved or not. New documents should only be fetched if there is either no history present yet or when the user&#x27;s question calls for a new retrieval. We make this decision by asking an LLM which way we should go in case there is already history present.</p>
<p>If documents should be fetched, we continue to retrieval. If not, we go to answering the question directly with documents that were previously retrieved and are present in the chat history.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="hyde">HyDE<a href="#hyde" class="hash-link" aria-label="Direct link to HyDE" title="Direct link to HyDE">​</a></h3>
<p>When using any RAG system, there is an inherent mismatch between the indexing phase and the query phase. When indexing our document chunks, we are essentially working with (potential) <em>answers</em>. Whenever a user poses a query, this is a <em>question</em>. When we just naively embed the chunks and the question in exactly the same way, we are comparing apples to oranges, though we expect there to be some coherence between the two.</p>
<p>Nonetheless, HyDE (Hypothetical Document Embeddings) tries to remedy this by generating a couple of documents with a given query. We do this by asking the LLM to generate those documents. This way we hope to compare apples with apples by using the answers generated with the query instead for retrieving relevant document chunks. HyDE is an optional step in RAG Me Up.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="document-retrieval">Document Retrieval<a href="#document-retrieval" class="hash-link" aria-label="Direct link to Document Retrieval" title="Direct link to Document Retrieval">​</a></h3>
<p>For query-time this is obviously the most crucial step to perform. Here we query the (hybrid) database to fetch documents (chunks) that are relevant to the user&#x27;s question. This is done by firing a SQL query to the Postgres system holding the dense and sparse vectors. The SQL query itself already scores the retrieved document chunks on similarity (using cosime similarity and BM25 score in a 50/50 weighing).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="reranking">Reranking<a href="#reranking" class="hash-link" aria-label="Direct link to Reranking" title="Direct link to Reranking">​</a></h3>
<p>One of the issues with a normal RAG pipeline&#x27;s scoring is that the document chunks are embedded in isolation and so is the user query. While this is relatively fast and can be done asynchronously, an alternative would be to use cross-encoders or other models that embed the document chunk together with the query to capture attention across both. This is what a reranker aims to do. The problem however is that this is too time-consuming to do for the entire document set. As a solution however, we can apply a reranker only on those documents that were retrieved by the regular retrieval process and rerank them. A good practice then is to retrieve a relatively large set directly from the database and then return a smaller subset of documents after reranking. RAG Me Up uses <a href="https://github.com/PrithivirajDamodaran/FlashRank" target="_blank" rel="noopener noreferrer">flashrank</a> for reranking as an optional step.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="answer-check---llm-as-a-judge">Answer Check - LLM-as-a-judge<a href="#answer-check---llm-as-a-judge" class="hash-link" aria-label="Direct link to Answer Check - LLM-as-a-judge" title="Direct link to Answer Check - LLM-as-a-judge">​</a></h3>
<p>Once documents are retrieved and ranked, we can use a form of self-inflection or LLM-as-a-judge to determine whether or not the currently retrieved set of chunks <em>can</em> accurately answer the user&#x27;s question. If this is not the case, we can rewrite the original user&#x27;s question in an attempt to obtain better document chunks in a new retrieval round. RAG Me Up allows this rewriting loop to be turned on as an optional step and will only perform it once to prevent too lengthy or even infinite rewrites.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="re2">Re2<a href="#re2" class="hash-link" aria-label="Direct link to Re2" title="Direct link to Re2">​</a></h3>
<p>It has been shown that <a href="https://arxiv.org/abs/2309.06275" target="_blank" rel="noopener noreferrer">instructing an LLM to re-read a question</a> - called Re2 - benefits the quality of the answer given by the LLM. Re2 is an optional step in RAG Me Up.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-creation">Prompt Creation<a href="#prompt-creation" class="hash-link" aria-label="Direct link to Prompt Creation" title="Direct link to Prompt Creation">​</a></h3>
<p>When the question is potentially remodeled and the documents are finalized to be inject, RAG Me Up will set up a prompt with documents inserted into it and feed the full prompt to the LLM and get the reply back.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="provenance-attribution">Provenance Attribution<a href="#provenance-attribution" class="hash-link" aria-label="Direct link to Provenance Attribution" title="Direct link to Provenance Attribution">​</a></h3>
<p>Once the LLM has given an answer to the user&#x27;s question, a RAG pipeline usually finalizes its query-phase and returns it to the client. In some applications of RAG however, it can be crucial to understand what documents were <strong>actually</strong> used by the LLM to generate the answer. While, even after reranking, we feed a set of &quot;as-relevant-as-possible&quot; documents to the LLM it may still choose to use some more than others or even ignore some altogether.</p>
<p>Provenance attribtuion tries to assign a score to each document chunk to indicate how relevant it was in generating the answer in hindsight. There are different ways of doing this and RAG Me Up provides provenance attribution as an optional step.</p>
<!-- -->
<section data-footnotes="true" class="footnotes"><h2 class="anchor anchorWithStickyNavbar_LWe7 sr-only" id="footnote-label">Footnotes<a href="#footnote-label" class="hash-link" aria-label="Direct link to Footnotes" title="Direct link to Footnotes">​</a></h2>
<ol>
<li id="user-content-fn-1">
<p>While overly simplified; LMs are Language Models like the BERT-family of models and are good are converting text into semantic-preserving vectors. They are not to be confused with LLMs (Large Language Models) which generally <em>generate</em> text. This goed without saying that LLMs <em>also</em> create vectors for any text and hence can often be used as embedding models too. <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1" class="data-footnote-backref">↩</a></p>
</li>
</ol>
</section></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/architecture.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/intro_rag"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">An introduction to RAG (and AI)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/env"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Configuring the .env File</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#high-level-pipeline-explanation" class="table-of-contents__link toc-highlight">High Level Pipeline Explanation</a><ul><li><a href="#your-documents" class="table-of-contents__link toc-highlight">Your Documents</a></li><li><a href="#loaders" class="table-of-contents__link toc-highlight">Loaders</a></li><li><a href="#chunking" class="table-of-contents__link toc-highlight">Chunking</a></li><li><a href="#document-embeddings" class="table-of-contents__link toc-highlight">Document Embeddings</a></li><li><a href="#sparse-bm25-vector-store" class="table-of-contents__link toc-highlight">Sparse BM25 Vector store</a></li><li><a href="#dense-vector-db" class="table-of-contents__link toc-highlight">Dense Vector DB</a></li><li><a href="#query-user-interface" class="table-of-contents__link toc-highlight">Query (User Interface)</a></li><li><a href="#history-summarization" class="table-of-contents__link toc-highlight">History Summarization</a></li><li><a href="#document-fetch-check" class="table-of-contents__link toc-highlight">Document Fetch Check</a></li><li><a href="#hyde" class="table-of-contents__link toc-highlight">HyDE</a></li><li><a href="#document-retrieval" class="table-of-contents__link toc-highlight">Document Retrieval</a></li><li><a href="#reranking" class="table-of-contents__link toc-highlight">Reranking</a></li><li><a href="#answer-check---llm-as-a-judge" class="table-of-contents__link toc-highlight">Answer Check - LLM-as-a-judge</a></li><li><a href="#re2" class="table-of-contents__link toc-highlight">Re2</a></li><li><a href="#prompt-creation" class="table-of-contents__link toc-highlight">Prompt Creation</a></li><li><a href="#provenance-attribution" class="table-of-contents__link toc-highlight">Provenance Attribution</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Documentation</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 FutureClub. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>